{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8247583a-5bb7-4a7c-8efa-9d2d4043c59f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## customers table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29887dd7-31b4-4da0-a790-21736d4983f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks data profile. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\nif hasattr(dbutils, \"data\") and hasattr(dbutils.data, \"summarize\"):\n  # setup\n  __data_summary_display_orig = display\n  __data_summary_dfs = []\n  def __data_summary_display_new(df):\n    # add only when result is going to be table type\n    __data_summary_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\", \"pyspark.sql.classic.dataframe\"]\n    if (type(df).__module__ in __data_summary_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n      __data_summary_dfs.append(df)\n  display = __data_summary_display_new\n\n  def __data_summary_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"cXVlcnkgPSAiU0VMRUNUICogRlJPTSBkYXRhYnJpY2tzX3NpbXVsYXRlZF9yZXRhaWxfY3VzdG9tZXJfZGF0YS52MDEuY3VzdG9tZXJzIgpjdXN0b21lcnNfZGYgPSBzcGFyay5zcWwocXVlcnkpCmRpc3BsYXkoY3VzdG9tZXJzX2RmKQ==\").decode())\n\n  try:\n    # run user code\n    __data_summary_user_code_fn()\n\n    # run on valid tableResultIndex\n    if len(__data_summary_dfs) > 0:\n      # run summarize\n      if type(__data_summary_dfs[0]).__module__ == \"databricks.koalas.frame\":\n        # koalas dataframe\n        dbutils.data.summarize(__data_summary_dfs[0].to_spark())\n      elif type(__data_summary_dfs[0]).__module__ == \"pandas.core.frame\":\n        # pandas dataframe\n        dbutils.data.summarize(spark.createDataFrame(__data_summary_dfs[0]))\n      else:\n        dbutils.data.summarize(__data_summary_dfs[0])\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n  finally:\n    display = __data_summary_display_orig\n    del __data_summary_display_new\n    del __data_summary_display_orig\n    del __data_summary_dfs\n    del __data_summary_user_code_fn\nelse:\n  print(\"This DBR version does not support data profiles.\")",
       "commandTitle": "데이터 프로필 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {},
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "table",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 1755591891883,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": [
        [
         "mimeBundle",
         null
        ]
       ],
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "e05c3d3f-aca1-42ac-ac31-f30c7a92d909",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 2.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 1755591823929,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": null,
       "submitTime": 1755591424507,
       "subtype": "tableResultSubCmd.dataSummary",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"SELECT * FROM databricks_simulated_retail_customer_data.v01.customers\"\n",
    "customers_df = spark.sql(query)\n",
    "display(customers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "197bb5d3-cd23-48fe-83f7-f621ca073713",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 必要ないカラムの削除\n",
    "exclude_cols = [\n",
    "    \"tax_id\", \"tax_code\", \"customer_name\", \"postcode\", \"street\", \"number\",\n",
    "    \"unit\", \"region\", \"district\", \"lon\", \"lat\", \"ship_to_address\", \"valid_from\", \"valid_to\"\n",
    "]\n",
    "\n",
    "selected_cols = [col for col in customers_df.columns if col not in exclude_cols]\n",
    "\n",
    "print(\"[\" + \", \".join(selected_cols) + \"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea7602de-6135-4bfc-a06b-b45a117d46a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  customer_id,\n",
    "  state,\n",
    "  city,\n",
    "  units_purchased,\n",
    "  loyalty_segment\n",
    "FROM\n",
    "  databricks_simulated_retail_customer_data.v01.customers\n",
    "where\n",
    "  units_purchased is not null\n",
    "  and loyalty_segment is not null\n",
    "  and state is not null\n",
    "  and city is not null\n",
    "  and trim(units_purchased) != ''\n",
    "  and trim(loyalty_segment) != ''\n",
    "  and trim(state) != ''\n",
    "  and trim(city) != ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d07435e4-c61c-41da-8ac0-bc48c1246a09",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755234196380}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "  customer_id,\n",
    "  state,\n",
    "  city,\n",
    "  units_purchased,\n",
    "  loyalty_segment\n",
    "FROM\n",
    "  databricks_simulated_retail_customer_data.v01.customers\n",
    "where\n",
    "  units_purchased is not null\n",
    "  and loyalty_segment is not null\n",
    "  and state is not null\n",
    "  and city is not null\n",
    "  and trim(units_purchased) != ''\n",
    "  and trim(loyalty_segment) != ''\n",
    "  and trim(state) != ''\n",
    "  and trim(city) != ''\n",
    "\"\"\"\n",
    "\n",
    "customers_df_cleansing = spark.sql(query)\n",
    "display(customers_df_cleansing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7042a439-e39f-44a4-a91e-ab60d4d2df51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## sales table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a56b3a7a-c9bd-41db-a5c5-c2224a35c74c",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755483804837}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks data profile. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\nif hasattr(dbutils, \"data\") and hasattr(dbutils.data, \"summarize\"):\n  # setup\n  __data_summary_display_orig = display\n  __data_summary_dfs = []\n  def __data_summary_display_new(df):\n    # add only when result is going to be table type\n    __data_summary_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\", \"pyspark.sql.classic.dataframe\"]\n    if (type(df).__module__ in __data_summary_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n      __data_summary_dfs.append(df)\n  display = __data_summary_display_new\n\n  def __data_summary_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"cXVlcnkgPSAiU0VMRUNUICogRlJPTSBkYXRhYnJpY2tzX3NpbXVsYXRlZF9yZXRhaWxfY3VzdG9tZXJfZGF0YS52MDEuc2FsZXMiCnNhbGVzX2RmID0gc3Bhcmsuc3FsKHF1ZXJ5KQpkaXNwbGF5KHNhbGVzX2RmKQ==\").decode())\n\n  try:\n    # run user code\n    __data_summary_user_code_fn()\n\n    # run on valid tableResultIndex\n    if len(__data_summary_dfs) > 0:\n      # run summarize\n      if type(__data_summary_dfs[0]).__module__ == \"databricks.koalas.frame\":\n        # koalas dataframe\n        dbutils.data.summarize(__data_summary_dfs[0].to_spark())\n      elif type(__data_summary_dfs[0]).__module__ == \"pandas.core.frame\":\n        # pandas dataframe\n        dbutils.data.summarize(spark.createDataFrame(__data_summary_dfs[0]))\n      else:\n        dbutils.data.summarize(__data_summary_dfs[0])\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n  finally:\n    display = __data_summary_display_orig\n    del __data_summary_display_new\n    del __data_summary_display_orig\n    del __data_summary_dfs\n    del __data_summary_user_code_fn\nelse:\n  print(\"This DBR version does not support data profiles.\")",
       "commandTitle": "데이터 프로필 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {},
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "table",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 1755591916870,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": [
        [
         "mimeBundle",
         null
        ]
       ],
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "f9cb84b8-d72a-4383-ae0c-f1c8f396436d",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 2.84375,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 1755591907380,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": null,
       "submitTime": 1755591424533,
       "subtype": "tableResultSubCmd.dataSummary",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"SELECT * FROM databricks_simulated_retail_customer_data.v01.sales\"\n",
    "sales_df = spark.sql(query)\n",
    "display(sales_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d640dc41-f1cb-4057-bf15-b823fb80f5f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 必要ないカラムの削除\n",
    "exclude_cols = [\n",
    "    \"customer_name\"\n",
    "]\n",
    "\n",
    "selected_cols = [col for col in sales_df.columns if col not in exclude_cols]\n",
    "\n",
    "print(\"[\" + \", \".join(selected_cols) + \"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c9b9c57-79a4-4d22-88e6-b94c2a1b30cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "  customer_id,\n",
    "  product_name,\n",
    "  order_date,\n",
    "  product_category,\n",
    "  product,\n",
    "  total_price\n",
    "FROM\n",
    "  databricks_simulated_retail_customer_data.v01.sales\n",
    "WHERE\n",
    "  customer_id IS NOT NULL\n",
    "  AND product_name IS NOT NULL\n",
    "  AND order_date IS NOT NULL\n",
    "  AND product_category IS NOT NULL\n",
    "  AND product IS NOT NULL\n",
    "  AND total_price IS NOT NULL\n",
    "  AND TRIM(customer_id) != ''\n",
    "  AND TRIM(product_name) != ''\n",
    "  AND TRIM(order_date) != ''\n",
    "  AND TRIM(product_category) != ''\n",
    "  AND TRIM(product) != ''\n",
    "  AND TRIM(total_price) != ''\n",
    "\"\"\"\n",
    "\n",
    "sales_df_cleansing = spark.sql(query)\n",
    "display(sales_df_cleansing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "079523c9-8e15-4dbf-b2ff-e6129d31a06f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## sales_orders table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "474629e4-ba0d-4495-9629-371f93f9e4fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks data profile. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\nif hasattr(dbutils, \"data\") and hasattr(dbutils.data, \"summarize\"):\n  # setup\n  __data_summary_display_orig = display\n  __data_summary_dfs = []\n  def __data_summary_display_new(df):\n    # add only when result is going to be table type\n    __data_summary_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\", \"pyspark.sql.classic.dataframe\"]\n    if (type(df).__module__ in __data_summary_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n      __data_summary_dfs.append(df)\n  display = __data_summary_display_new\n\n  def __data_summary_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"cXVlcnkgPSAiU0VMRUNUICogRlJPTSBkYXRhYnJpY2tzX3NpbXVsYXRlZF9yZXRhaWxfY3VzdG9tZXJfZGF0YS52MDEuc2FsZXNfb3JkZXJzIgpzYWxlc19vcmRlcnNfZGYgPSBzcGFyay5zcWwocXVlcnkpCmRpc3BsYXkoc2FsZXNfb3JkZXJzX2RmKQ==\").decode())\n\n  try:\n    # run user code\n    __data_summary_user_code_fn()\n\n    # run on valid tableResultIndex\n    if len(__data_summary_dfs) > 0:\n      # run summarize\n      if type(__data_summary_dfs[0]).__module__ == \"databricks.koalas.frame\":\n        # koalas dataframe\n        dbutils.data.summarize(__data_summary_dfs[0].to_spark())\n      elif type(__data_summary_dfs[0]).__module__ == \"pandas.core.frame\":\n        # pandas dataframe\n        dbutils.data.summarize(spark.createDataFrame(__data_summary_dfs[0]))\n      else:\n        dbutils.data.summarize(__data_summary_dfs[0])\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n  finally:\n    display = __data_summary_display_orig\n    del __data_summary_display_new\n    del __data_summary_display_orig\n    del __data_summary_dfs\n    del __data_summary_user_code_fn\nelse:\n  print(\"This DBR version does not support data profiles.\")",
       "commandTitle": "데이터 프로필 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {},
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "table",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 1755591932608,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": [
        [
         "mimeBundle",
         null
        ]
       ],
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "42795721-5874-4703-8b4b-f0d47f1dd5c1",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 4.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 1755591923759,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": null,
       "submitTime": 1755591424547,
       "subtype": "tableResultSubCmd.dataSummary",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"SELECT * FROM databricks_simulated_retail_customer_data.v01.sales_orders\"\n",
    "sales_orders_df = spark.sql(query)\n",
    "display(sales_orders_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f10a5cd-be67-4189-b148-6e00bc85b7ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 必要ないカラムの削除\n",
    "exclude_cols = [\n",
    "    \"customer_name\"\n",
    "]\n",
    "\n",
    "selected_cols = [col for col in sales_orders_df.columns if col not in exclude_cols]\n",
    "\n",
    "print(\"[\" + \", \".join(selected_cols) + \"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0165b4cb-e59f-47ba-957a-0ea7641acc2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "  clicked_items,\n",
    "  customer_id,\n",
    "  number_of_line_items,\n",
    "  from_unixtime(CAST(order_datetime AS BIGINT)) AS order_datetime,\n",
    "  order_number,\n",
    "  ordered_products,\n",
    "  promo_info\n",
    "FROM\n",
    "  databricks_simulated_retail_customer_data.v01.sales_orders\n",
    "WHERE\n",
    "  customer_id IS NOT NULL\n",
    "  AND clicked_items IS NOT NULL\n",
    "  AND number_of_line_items IS NOT NULL\n",
    "  AND order_datetime IS NOT NULL\n",
    "  AND order_number IS NOT NULL\n",
    "  AND ordered_products IS NOT NULL\n",
    "  AND promo_info IS NOT NULL\n",
    "  AND TRIM(customer_id) != ''\n",
    "  AND TRIM(clicked_items) != ''\n",
    "  AND TRIM(number_of_line_items) != ''\n",
    "  AND TRIM(order_datetime) != ''\n",
    "  AND TRIM(order_number) != ''\n",
    "  AND TRIM(ordered_products) != ''\n",
    "  AND TRIM(promo_info) != ''\n",
    "\"\"\"\n",
    "\n",
    "sales_orders_df_cleansing = spark.sql(query)\n",
    "display(sales_orders_df_cleansing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5d6bcb2-013d-464d-a5b5-f716a176d27b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# query = \"\"\"\n",
    "# WITH base AS (\n",
    "#   SELECT\n",
    "#     clicked_items,\n",
    "#     customer_id,\n",
    "#     number_of_line_items,\n",
    "#     from_unixtime(CAST(order_datetime AS BIGINT)) AS order_datetime,\n",
    "#     order_number,\n",
    "#     ordered_products,\n",
    "#     promo_info\n",
    "#   FROM\n",
    "#     databricks_simulated_retail_customer_data.v01.sales_orders\n",
    "#   WHERE\n",
    "#     customer_id IS NOT NULL\n",
    "#     AND clicked_items IS NOT NULL\n",
    "#     AND number_of_line_items IS NOT NULL\n",
    "#     AND order_datetime IS NOT NULL\n",
    "#     AND order_number IS NOT NULL\n",
    "#     AND ordered_products IS NOT NULL\n",
    "#     AND promo_info IS NOT NULL\n",
    "#     AND TRIM(customer_id) != ''\n",
    "#     AND TRIM(clicked_items) != ''\n",
    "#     AND TRIM(number_of_line_items) != ''\n",
    "#     AND TRIM(order_datetime) != ''\n",
    "#     AND TRIM(order_number) != ''\n",
    "#     AND TRIM(ordered_products) != ''\n",
    "#     AND TRIM(promo_info) != ''\n",
    "# ),\n",
    "# exploded AS (\n",
    "#   SELECT\n",
    "#     clicked_items,\n",
    "#     customer_id,\n",
    "#     number_of_line_items,\n",
    "#     order_datetime,\n",
    "#     order_number,\n",
    "#     promo_info,\n",
    "#     p.curr  AS currency,\n",
    "#     p.id    AS product_id,\n",
    "#     p.name  AS product_name,\n",
    "#     p.price AS price,\n",
    "#     p.promotion_info AS item_promotion_info,\n",
    "#     p.qty   AS qty,\n",
    "#     p.unit  AS unit\n",
    "#   FROM base\n",
    "#   LATERAL VIEW EXPLODE(FROM_JSON(ordered_products,\n",
    "#     'ARRAY<STRUCT<curr:STRING,id:STRING,name:STRING,price:STRING,promotion_info:STRING,qty:STRING,unit:STRING>>')) t AS p\n",
    "# )\n",
    "# SELECT * FROM exploded\n",
    "# \"\"\"\n",
    "\n",
    "# sales_orders_df_cleansing = spark.sql(query)\n",
    "# display(sales_orders_df_cleansing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cac86e2f-4a18-4406-8666-9dee953bd7d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## table join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a67c4b27-603c-4045-8e97-cee174ea230a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "joined_df = customers_df_cleansing.join(\n",
    "    sales_df_cleansing, on=\"customer_id\", how=\"inner\"\n",
    ").join(\n",
    "    sales_orders_df_cleansing, on=\"customer_id\", how=\"inner\"\n",
    ")\n",
    "\n",
    "display(joined_df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5510389016166694,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01. EDA",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
