{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05dc4d60-4670-4182-a583-1f7400a50dfd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "from mlflow.exceptions import RestException\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "abde61ff-ac58-4b7f-856a-aaf5e0e76ffb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interactions = spark.table(\"MLOps.data.als_interactions_30d\")\n",
    "\n",
    "product_indexer = StringIndexer(\n",
    "    inputCol=\"product_id\",\n",
    "    outputCol=\"product_id_idx\",\n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "interactions_indexed = product_indexer.fit(interactions).transform(interactions)\n",
    "\n",
    "als = ALS(\n",
    "    userCol=\"customer_id\",\n",
    "    itemCol=\"product_id_idx\",\n",
    "    ratingCol=\"interaction_weight\",\n",
    "    implicitPrefs=True,\n",
    "    coldStartStrategy=\"drop\",\n",
    "    rank=20,\n",
    "    maxIter=10,\n",
    "    regParam=0.1\n",
    ")\n",
    "\n",
    "experiment_path = \"/Workspace/Users/jung@ap-com.co.jp/mlops_demo_model/als_recommendation\"\n",
    "\n",
    "try:\n",
    "    mlflow.set_experiment(experiment_path)\n",
    "    print(f\"Experiment found or created at: {experiment_path}\")\n",
    "\n",
    "except RestException as e:\n",
    "    if \"RESOURCE_DOES_NOT_EXIST\" in str(e):\n",
    "        experiment_id = mlflow.create_experiment(experiment_path)\n",
    "        mlflow.set_experiment(experiment_path)\n",
    "        print(f\"Experiment created at: {experiment_path}, ID: {experiment_id}\")\n",
    "    else:\n",
    "        raise e\n",
    "\n",
    "train, test = interactions_indexed.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "with mlflow.start_run(run_name=\"training\") as run:\n",
    "    model = als.fit(interactions_indexed)\n",
    "\n",
    "    predictions = model.transform(test)\n",
    "\n",
    "    sample_input = test.limit(5).toPandas()\n",
    "    sample_output = predictions.limit(5).toPandas()\n",
    "    signature = infer_signature(sample_input, sample_output)\n",
    "\n",
    "    mlflow.spark.log_model(\n",
    "        spark_model=model,\n",
    "        artifact_path=\"als_model\",\n",
    "        signature=signature\n",
    "    )\n",
    "\n",
    "    mlflow.log_params({\n",
    "        \"rank\": 20,\n",
    "        \"maxIter\": 10,\n",
    "        \"regParam\": 0.1\n",
    "    })\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "print(f\"Training finished. Run ID: {run_id}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01. Model Traing",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
