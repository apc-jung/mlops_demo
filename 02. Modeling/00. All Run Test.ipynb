{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05dc4d60-4670-4182-a583-1f7400a50dfd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "from mlflow.exceptions import RestException\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abde61ff-ac58-4b7f-856a-aaf5e0e76ffb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interactions = spark.table(\"MLOps.data.als_interactions_30d\")\n",
    "\n",
    "product_indexer = StringIndexer(\n",
    "    inputCol=\"product_id\",\n",
    "    outputCol=\"product_id_idx\",\n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "interactions_indexed = product_indexer.fit(interactions).transform(interactions)\n",
    "\n",
    "# als = ALS(\n",
    "#     userCol=\"customer_id\",\n",
    "#     itemCol=\"product_id_idx\",\n",
    "#     ratingCol=\"interaction_weight\",\n",
    "#     implicitPrefs=True,\n",
    "#     coldStartStrategy=\"drop\",\n",
    "#     rank=20,\n",
    "#     maxIter=10,\n",
    "#     regParam=0.1\n",
    "# )\n",
    "\n",
    "# als = ALS(\n",
    "#     userCol=\"customer_id\",\n",
    "#     itemCol=\"product_id_idx\",\n",
    "#     ratingCol=\"interaction_weight\",\n",
    "#     implicitPrefs=True,\n",
    "#     coldStartStrategy=\"drop\",\n",
    "#     rank=40,\n",
    "#     maxIter=15,\n",
    "#     regParam=0.05\n",
    "# )\n",
    "\n",
    "als = ALS(\n",
    "    userCol=\"customer_id\",\n",
    "    itemCol=\"product_id_idx\",\n",
    "    ratingCol=\"interaction_weight\",\n",
    "    implicitPrefs=True,\n",
    "    coldStartStrategy=\"drop\",\n",
    "    rank=10,\n",
    "    maxIter=15,\n",
    "    regParam=0.05\n",
    ")\n",
    "\n",
    "experiment_path = \"/Workspace/Users/jung@ap-com.co.jp/mlops_demo_model/als_recommendation\"\n",
    "\n",
    "try:\n",
    "    mlflow.set_experiment(experiment_path)\n",
    "    print(f\"Experiment found or created at: {experiment_path}\")\n",
    "\n",
    "except RestException as e:\n",
    "    if \"RESOURCE_DOES_NOT_EXIST\" in str(e):\n",
    "        experiment_id = mlflow.create_experiment(experiment_path)\n",
    "        mlflow.set_experiment(experiment_path)\n",
    "        print(f\"Experiment created at: {experiment_path}, ID: {experiment_id}\")\n",
    "    else:\n",
    "        raise e\n",
    "\n",
    "with mlflow.start_run(run_name=\"training\") as run:\n",
    "    model = als.fit(interactions_indexed)\n",
    "    mlflow.spark.log_model(model, \"als_model\")\n",
    "    mlflow.log_params({\n",
    "        \"rank\": 20,\n",
    "        \"maxIter\": 10,\n",
    "        \"regParam\": 0.1\n",
    "    })\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "print(f\"Training finished. Run ID: {run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7f0be05-c379-45d5-8052-e000ef2babbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import mlflow\n",
    "\n",
    "interactions = spark.table(\"MLOps.data.als_interactions_30d\")\n",
    "\n",
    "product_indexer = StringIndexer(\n",
    "    inputCol=\"product_id\",\n",
    "    outputCol=\"product_id_idx\",\n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "interactions_indexed = product_indexer.fit(interactions).transform(interactions)\n",
    "\n",
    "train, test = interactions_indexed.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "experiment_path = \"/Workspace/Users/jung@ap-com.co.jp/mlops_demo_model/als_recommendation\"\n",
    "experiment = mlflow.get_experiment_by_name(experiment_path)\n",
    "\n",
    "runs_df = mlflow.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id]\n",
    ")\n",
    "training_runs = runs_df[runs_df[\"tags.mlflow.runName\"] == \"training\"]\n",
    "latest_training_run = training_runs.sort_values(\n",
    "    by=\"start_time\", ascending=False\n",
    ").iloc[0]\n",
    "\n",
    "model_uri = f\"runs:/{latest_training_run.run_id}/als_model\"\n",
    "model = mlflow.spark.load_model(model_uri)\n",
    "print(model_uri)\n",
    "\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"interaction_weight\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "with mlflow.start_run(run_name=\"evaluation\") as run:\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    print(f\"Evaluation finished. RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95fc9052-dbf6-423b-a035-ed33d7c0ebfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "model_name = \"als_recommendation_model\"\n",
    "\n",
    "challenger = mlflow.spark.load_model(model_uri)\n",
    "\n",
    "try:\n",
    "    champion = mlflow.spark.load_model(f\"models:/{model_name}/Production\")\n",
    "    print(\"Champion model exists in Production\")\n",
    "except Exception as e:\n",
    "    champion = None\n",
    "    print(\"No Champion model found. Challenger will be promoted directly.\", e)\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"interaction_weight\",  \n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "predictions_challenger = challenger.transform(test)\n",
    "challenger_rmse = evaluator.evaluate(predictions_challenger)\n",
    "print(\"Challenger RMSE:\", challenger_rmse)\n",
    "\n",
    "if champion is not None:\n",
    "    predictions_champion = champion.transform(test)\n",
    "    champion_rmse = evaluator.evaluate(predictions_champion)\n",
    "    print(\"Champion RMSE:\", champion_rmse)\n",
    "else:\n",
    "    champion_rmse = None\n",
    "\n",
    "if champion is None or challenger_rmse < champion_rmse:\n",
    "    print(\"Challenger outperforms Champion (or no Champion exists). Promoting...\")\n",
    "\n",
    "    mlflow.register_model(model_uri, model_name)\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "    latest_version = client.get_latest_versions(model_name, stages=[\"None\"])[-1].version\n",
    "\n",
    "    client.transition_model_version_stage(\n",
    "        name=model_name,\n",
    "        version=latest_version,\n",
    "        stage=\"Production\",\n",
    "        archive_existing_versions=True\n",
    "    )\n",
    "    print(\"Challenger promoted to Champion (Production).\")\n",
    "else:\n",
    "    print(\"Challenger did not outperform Champion. No promotion.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "586daca5-9d56-4f42-b828-5d3c241e9bbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## 1回\n",
    "Champion model exists in Production\n",
    "Challenger RMSE: 0.9687680445911088\n",
    "Champion RMSE: 0.9687680445911088\n",
    "Challenger did not outperform Champion. No promotion.\n",
    "\n",
    "## 2回\n",
    "Champion model exists in Production\n",
    "Challenger RMSE: 0.8180663645429364\n",
    "Champion RMSE: 0.9687680445911088\n",
    "Challenger outperforms Champion (or no Champion exists). Promoting...\n",
    "\n",
    "## 3回\n",
    "Champion model exists in Production\n",
    "Challenger RMSE: 1.0672939052826609\n",
    "Champion RMSE: 0.8180663645429364\n",
    "Challenger did not outperform Champion. No promotion."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00. All Run Test",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
